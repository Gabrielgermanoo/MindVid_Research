{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (3.8.4)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 30.7/42.0 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 675.1 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabriel_germano\\documents\\pesquisa\\mindvid_research\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.4/268.4 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00\n",
      "Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.0 nltk-3.8.1 regex-2024.4.16 tqdm-4.66.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gabriel_Germano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['é a maior é a melhor técnica e os estudos falam e a técnica mais conhecida no mundo que se chama Ground se consiste na ativação dos órgãos no sentido né muitos alunos fazem esse momentos difíceis as vésperas de provas e isso tem salvado tanta gente luds você pega o seu rosto agora nesse momento e aí você coloca cinco nos olhos quatro no nariz três na boca dois no ouvido e um lotado Então você com os olhos fechados você vai imaginar cinco coisas que você pode ver é para fechar cinco coisas Qualquer coisa Qualquer coisa quatro coisas que você pode sentir o cheiro três coisas que você pode sentir o sabor dois sons']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "df = pd.read_csv(\"./Videos/ansiedade_audio_transcriptions.csv\")\n",
    "df.head()\n",
    "sent_tokenize(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é a maior é a melhor técnica e os estudos fala...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[é, a, maior, é, a, melhor, técnica, e, os, es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O que é que fez assim e assim e você aí você V...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[O, que, é, que, fez, assim, e, assim, e, você...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ficar olhando para as anotações para as mãos é...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[ficar, olhando, para, as, anotações, para, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4 coisas que você precisa saber se você namora...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[4, coisas, que, você, precisa, saber, se, voc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                      Transcription        tag  \\\n",
       "0   0  é a maior é a melhor técnica e os estudos fala...  ansiedade   \n",
       "1   1  O que é que fez assim e assim e você aí você V...  ansiedade   \n",
       "2   2  ficar olhando para as anotações para as mãos é...  ansiedade   \n",
       "3   3  4 coisas que você precisa saber se você namora...  ansiedade   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0  [é, a, maior, é, a, melhor, técnica, e, os, es...  \n",
       "1  [O, que, é, que, fez, assim, e, assim, e, você...  \n",
       "2  [ficar, olhando, para, as, anotações, para, as...  \n",
       "3  [4, coisas, que, você, precisa, saber, se, voc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_words'] = df['Transcription'].apply(lambda x: word_tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gabriel_Germano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>removed_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é a maior é a melhor técnica e os estudos fala...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[é, a, maior, é, a, melhor, técnica, e, os, es...</td>\n",
       "      <td>[maior, melhor, técnica, estudos, falam, técni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O que é que fez assim e assim e você aí você V...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[O, que, é, que, fez, assim, e, assim, e, você...</td>\n",
       "      <td>[fez, assim, assim, aí, fez, quê, príncipe, aí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ficar olhando para as anotações para as mãos é...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[ficar, olhando, para, as, anotações, para, as...</td>\n",
       "      <td>[ficar, olhando, anotações, mãos, deprimente, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4 coisas que você precisa saber se você namora...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[4, coisas, que, você, precisa, saber, se, voc...</td>\n",
       "      <td>[4, coisas, precisa, saber, namora, pessoa, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                      Transcription        tag  \\\n",
       "0   0  é a maior é a melhor técnica e os estudos fala...  ansiedade   \n",
       "1   1  O que é que fez assim e assim e você aí você V...  ansiedade   \n",
       "2   2  ficar olhando para as anotações para as mãos é...  ansiedade   \n",
       "3   3  4 coisas que você precisa saber se você namora...  ansiedade   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  [é, a, maior, é, a, melhor, técnica, e, os, es...   \n",
       "1  [O, que, é, que, fez, assim, e, assim, e, você...   \n",
       "2  [ficar, olhando, para, as, anotações, para, as...   \n",
       "3  [4, coisas, que, você, precisa, saber, se, voc...   \n",
       "\n",
       "                                   removed_stopwords  \n",
       "0  [maior, melhor, técnica, estudos, falam, técni...  \n",
       "1  [fez, assim, assim, aí, fez, quê, príncipe, aí...  \n",
       "2  [ficar, olhando, anotações, mãos, deprimente, ...  \n",
       "3  [4, coisas, precisa, saber, namora, pessoa, an...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['removed_stopwords'] = df['tokenized_words'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Gabriel_Germano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>removed_stopwords</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é a maior é a melhor técnica e os estudos fala...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[é, a, maior, é, a, melhor, técnica, e, os, es...</td>\n",
       "      <td>[maior, melhor, técnica, estudos, falam, técni...</td>\n",
       "      <td>[é, a, mai, é, a, melhor, técn, e, os, estud, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O que é que fez assim e assim e você aí você V...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[O, que, é, que, fez, assim, e, assim, e, você...</td>\n",
       "      <td>[fez, assim, assim, aí, fez, quê, príncipe, aí...</td>\n",
       "      <td>[o, que, é, que, fez, assim, e, assim, e, voc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ficar olhando para as anotações para as mãos é...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[ficar, olhando, para, as, anotações, para, as...</td>\n",
       "      <td>[ficar, olhando, anotações, mãos, deprimente, ...</td>\n",
       "      <td>[fic, olh, par, as, anot, par, as, mão, é, dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4 coisas que você precisa saber se você namora...</td>\n",
       "      <td>ansiedade</td>\n",
       "      <td>[4, coisas, que, você, precisa, saber, se, voc...</td>\n",
       "      <td>[4, coisas, precisa, saber, namora, pessoa, an...</td>\n",
       "      <td>[4, cois, que, voc, precis, sab, se, voc, nam,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                      Transcription        tag  \\\n",
       "0   0  é a maior é a melhor técnica e os estudos fala...  ansiedade   \n",
       "1   1  O que é que fez assim e assim e você aí você V...  ansiedade   \n",
       "2   2  ficar olhando para as anotações para as mãos é...  ansiedade   \n",
       "3   3  4 coisas que você precisa saber se você namora...  ansiedade   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  [é, a, maior, é, a, melhor, técnica, e, os, es...   \n",
       "1  [O, que, é, que, fez, assim, e, assim, e, você...   \n",
       "2  [ficar, olhando, para, as, anotações, para, as...   \n",
       "3  [4, coisas, que, você, precisa, saber, se, voc...   \n",
       "\n",
       "                                   removed_stopwords  \\\n",
       "0  [maior, melhor, técnica, estudos, falam, técni...   \n",
       "1  [fez, assim, assim, aí, fez, quê, príncipe, aí...   \n",
       "2  [ficar, olhando, anotações, mãos, deprimente, ...   \n",
       "3  [4, coisas, precisa, saber, namora, pessoa, an...   \n",
       "\n",
       "                                            stemming  \n",
       "0  [é, a, mai, é, a, melhor, técn, e, os, estud, ...  \n",
       "1  [o, que, é, que, fez, assim, e, assim, e, voc,...  \n",
       "2  [fic, olh, par, as, anot, par, as, mão, é, dep...  \n",
       "3  [4, cois, que, voc, precis, sab, se, voc, nam,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "stemmer = RSLPStemmer()\n",
    "df['stemming'] = df['tokenized_words'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
